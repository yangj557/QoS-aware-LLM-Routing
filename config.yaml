# environment and task
env:
  version: env
  seed: 2024
  num_experts: 3
  lam: 3.0
  L: 0.03
  name: env_${env.lam}_${env.L}_${env.num_experts}

# collector
collector:
  total_frames: 1_000_000
  init_random_frames: 25000
  frames_per_batch: 5000
  device: cpu
  env_per_collector: 1
  reset_at_each_iter: False

# replay buffer
replay_buffer:
  size: 100000
  prb: 0 # use prioritized experience replay
  scratch_dir: null

# optim
optim:
  utd_ratio: 1.0
  gamma: 0.99
  loss_function: l2
  lr: 3.0e-5
  weight_decay: 0.0
  batch_size: 256
  target_update_polyak: 0.995
  alpha_init: 1.0
  adam_eps: 1.0e-8

# network
network:
  hidden_sizes: [64, 64]
  activation: relu
  default_policy_scale: 1.0
  scale_lb: 0.1
  device:

# logging
logger:
  backend: tensorboard
  project_name: torchrl_example_sac
  group_name: null
  exp_name: ${env.name}_SAC
  mode: online